{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/janestreet/data.parquet\n/kaggle/input/nn-result/nn_result.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This notebook's approach is using LSTM for times-series method."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nimport warnings\nwarnings.filterwarnings (\"ignore\")\nimport gc  \n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nSEED = 1111\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this data is already excluded day <= 85\n\ndata = pd.read_parquet('../input/janestreet/data.parquet')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select trade with weight !=  0:\ndata = data[data['weight'] != 0]\n# # limit memory use: we change datatype from float64 to float32\ndata = data.astype({c: np.float32 for c in data.select_dtypes(include='float64').columns}) \n\n# create target variable\ndata['action'] = (data['resp'] > 0)*1\n\n# fill null values with mean of each feature\ndata.fillna(data.mean(),inplace=True)\n\n#create fetures list\nfeatures = [c for c in data.columns if 'feature' in c]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 20 / 80 split\ndf_trainvalid, df_test = np.split(data, [int(.8*len(data))])\n\ndf_train, df_valid = np.split(df_trainvalid, [int(.9*len(df_trainvalid))])\n\nX_train = df_train[features]\ny_train = df_train['action']\n\nX_valid = df_valid[features]\ny_valid = df_valid['action']\n\nX_test = df_test[features]\ny_test = df_test['action']\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NORMALIZE_NONE = 0\nNORMALIZE_MIN_MAX = 1\nNORMALIZE_MEAN = 2\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_data(df):\n    if NORMALIZE_TYPE == NORMALIZE_MIN_MAX:\n        return (df-df.min())/(df.max()-df.min())\n    elif NORMALIZE_TYPE == NORMALIZE_MEAN:\n        return (df-df.mean())/df.std()\n    else:\n        return df;\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NORMALIZE_TYPE = NORMALIZE_MEAN\n\nX_train = normalize_data(X_train)\nX_valid = normalize_data(X_valid)\nX_test = normalize_data(X_test)\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_windows(data, window_shape, step = 1, start_id = None, end_id = None):\n    \n    data = np.asarray(data)\n    data = data.reshape(-1,1) if np.prod(data.shape) == max(data.shape) else data\n        \n    start_id = 0 if start_id is None else start_id\n    end_id = data.shape[0] if end_id is None else end_id\n    \n    data = data[int(start_id):int(end_id),:]\n    window_shape = (int(window_shape), data.shape[-1])\n    step = (int(step),) * data.ndim\n    slices = tuple(slice(None, None, st) for st in step)\n    indexing_strides = data[slices].strides\n    win_indices_shape = ((np.array(data.shape) - window_shape) // step) + 1\n    \n    new_shape = tuple(list(win_indices_shape) + list(window_shape))\n    strides = tuple(list(indexing_strides) + list(data.strides))\n    \n    window_data = np.lib.stride_tricks.as_strided(data, shape=new_shape, strides=strides)\n    \n    return np.squeeze(window_data, 1)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"look_back = 2\nlook_ahead = 1\n# LSTM expects 3D input (examples, timestep, features)\nX_train_reshaped = create_windows(X_train, window_shape=look_back).astype(np.float32)\ny_train_reshaped = create_windows(y_train, window_shape = look_ahead, start_id = look_back-1)\n\nX_valid_reshaped = create_windows(X_valid, window_shape=look_back).astype(np.float32)\ny_valid_reshaped = create_windows(y_valid, window_shape = look_ahead, start_id = look_back-1)\n\nX_test_reshaped = create_windows(X_test, window_shape=look_back).astype(np.float32)\ny_test_reshaped = create_windows(y_test, window_shape = look_ahead, start_id = look_back-1)\n\nprint(X_train_reshaped.shape, y_train_reshaped.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(1131417, 2, 130) (1131417, 1, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data, df_train, df_valid, df_trainvalid, X_train, X_valid, y_train, y_valid, X_test, y_test\ngc.collect()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"62"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 4096 \nstep_train = len(X_train_reshaped)//batch_size\nstep_valid = len(X_valid_reshaped)//batch_size\nstep_test = len(X_test_reshaped)//batch_size\n\n\n# # Create train, valid, test data with batch size \ntrain = tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train_reshaped)).batch(batch_size).repeat()\nval = tf.data.Dataset.from_tensor_slices((X_valid_reshaped, y_valid_reshaped)).batch(batch_size).repeat()\ntest = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test_reshaped)).batch(batch_size).repeat()\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train_reshaped, y_train_reshaped, X_valid_reshaped, y_valid_reshaped, y_test_reshaped\ngc.collect()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_r = 0.0001\n\n# A Sequential model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.LSTM(64, input_shape=(look_back,130),return_sequences=True),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(64),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate = l_r),metrics=[\"AUC\"])\n\nmodel.summary()\n","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 2, 64)             49920     \n_________________________________________________________________\ndropout (Dropout)            (None, 2, 64)             0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 64)                33024     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64)                256       \n_________________________________________________________________\ndense (Dense)                (None, 1)                 65        \n=================================================================\nTotal params: 83,265\nTrainable params: 83,137\nNon-trainable params: 128\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"7218"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel.fit(train, validation_data=val, epochs=35, steps_per_epoch = step_train, validation_steps = step_valid, verbose = 1,\n          callbacks = [EarlyStopping(monitor='val_loss', verbose=1, patience=10)])","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/35\n276/276 [==============================] - 11s 19ms/step - loss: 0.7613 - auc: 0.5030 - val_loss: 0.6934 - val_auc: 0.5066\nEpoch 2/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.7213 - auc: 0.5045 - val_loss: 0.6935 - val_auc: 0.5100\nEpoch 3/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.7141 - auc: 0.5051 - val_loss: 0.6937 - val_auc: 0.5101\nEpoch 4/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.7091 - auc: 0.5053 - val_loss: 0.6935 - val_auc: 0.5090\nEpoch 5/35\n276/276 [==============================] - 5s 18ms/step - loss: 0.7052 - auc: 0.5064 - val_loss: 0.6935 - val_auc: 0.5083\nEpoch 6/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.7028 - auc: 0.5069 - val_loss: 0.6936 - val_auc: 0.5087\nEpoch 7/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.7010 - auc: 0.5063 - val_loss: 0.6935 - val_auc: 0.5091\nEpoch 8/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6989 - auc: 0.5094 - val_loss: 0.6936 - val_auc: 0.5096\nEpoch 9/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6979 - auc: 0.5097 - val_loss: 0.6934 - val_auc: 0.5104\nEpoch 10/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.6969 - auc: 0.5107 - val_loss: 0.6934 - val_auc: 0.5117\nEpoch 11/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6960 - auc: 0.5128 - val_loss: 0.6934 - val_auc: 0.5122\nEpoch 12/35\n276/276 [==============================] - 5s 18ms/step - loss: 0.6954 - auc: 0.5137 - val_loss: 0.6934 - val_auc: 0.5129\nEpoch 13/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6948 - auc: 0.5154 - val_loss: 0.6933 - val_auc: 0.5133\nEpoch 14/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6943 - auc: 0.5165 - val_loss: 0.6933 - val_auc: 0.5137\nEpoch 15/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.6939 - auc: 0.5170 - val_loss: 0.6932 - val_auc: 0.5145\nEpoch 16/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6934 - auc: 0.5195 - val_loss: 0.6934 - val_auc: 0.5146\nEpoch 17/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.6931 - auc: 0.5208 - val_loss: 0.6934 - val_auc: 0.5151\nEpoch 18/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6929 - auc: 0.5213 - val_loss: 0.6933 - val_auc: 0.5154\nEpoch 19/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6927 - auc: 0.5225 - val_loss: 0.6934 - val_auc: 0.5158\nEpoch 20/35\n276/276 [==============================] - 5s 18ms/step - loss: 0.6926 - auc: 0.5227 - val_loss: 0.6934 - val_auc: 0.5155\nEpoch 21/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6924 - auc: 0.5234 - val_loss: 0.6934 - val_auc: 0.5159\nEpoch 22/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.6920 - auc: 0.5258 - val_loss: 0.6935 - val_auc: 0.5161\nEpoch 23/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6919 - auc: 0.5264 - val_loss: 0.6935 - val_auc: 0.5161\nEpoch 24/35\n276/276 [==============================] - 4s 15ms/step - loss: 0.6917 - auc: 0.5274 - val_loss: 0.6934 - val_auc: 0.5164\nEpoch 25/35\n276/276 [==============================] - 4s 16ms/step - loss: 0.6915 - auc: 0.5286 - val_loss: 0.6936 - val_auc: 0.5164\nEpoch 00025: early stopping\nCPU times: user 2min 3s, sys: 9.14 s, total: 2min 12s\nWall time: 1min 55s\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fdbc8101f90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test, steps = step_test)\n\nprint(\"test loss, test acc:\", results)","execution_count":17,"outputs":[{"output_type":"stream","text":"Evaluate on test data\n76/76 [==============================] - 1s 10ms/step - loss: 0.6914 - auc: 0.5314\ntest loss, test acc: [0.6914218068122864, 0.5313917994499207]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict_classes(X_test_reshaped).reshape(1,-1)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility score"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nresult_df = pd.DataFrame({'Date': df_test['date'][look_back-1:], 'Weight': df_test['weight'][look_back-1:],\n                          'Resp': df_test['resp'][look_back-1:], 'Action': prediction[0]})\n\nresult_df['P'] = result_df['Weight']*result_df['Resp']*result_df['Action']\nresult_df.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"         Date     Weight      Resp  Action         P\n1493257   430  11.982266 -0.004582       0 -0.000000\n1493258   430   1.107787 -0.004491       1 -0.004975\n1493259   430   1.312454  0.000542       1  0.000711\n1493260   430   0.422074 -0.004623       1 -0.001951\n1493261   430   2.849713 -0.011910       0 -0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Weight</th>\n      <th>Resp</th>\n      <th>Action</th>\n      <th>P</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1493257</th>\n      <td>430</td>\n      <td>11.982266</td>\n      <td>-0.004582</td>\n      <td>0</td>\n      <td>-0.000000</td>\n    </tr>\n    <tr>\n      <th>1493258</th>\n      <td>430</td>\n      <td>1.107787</td>\n      <td>-0.004491</td>\n      <td>1</td>\n      <td>-0.004975</td>\n    </tr>\n    <tr>\n      <th>1493259</th>\n      <td>430</td>\n      <td>1.312454</td>\n      <td>0.000542</td>\n      <td>1</td>\n      <td>0.000711</td>\n    </tr>\n    <tr>\n      <th>1493260</th>\n      <td>430</td>\n      <td>0.422074</td>\n      <td>-0.004623</td>\n      <td>1</td>\n      <td>-0.001951</td>\n    </tr>\n    <tr>\n      <th>1493261</th>\n      <td>430</td>\n      <td>2.849713</td>\n      <td>-0.011910</td>\n      <td>0</td>\n      <td>-0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_groupby_days = result_df[['Date', 'P']].groupby('Date').sum().reset_index()\nprint(result_groupby_days.shape)\nresult_groupby_days.head()","execution_count":20,"outputs":[{"output_type":"stream","text":"(70, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"   Date          P\n0   430  -3.440870\n1   431 -13.891810\n2   432  -3.721030\n3   433 -12.663742\n4   434   5.711499","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>P</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>430</td>\n      <td>-3.440870</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>431</td>\n      <td>-13.891810</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>432</td>\n      <td>-3.721030</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>433</td>\n      <td>-12.663742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>434</td>\n      <td>5.711499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = result_groupby_days['P'].values\n\nt = (np.sum(p)/(np.sqrt(np.sum(p**2))))*np.sqrt(250/len(p))\n\nu = min(max(t, 0), 6) * np.sum(p)\n\nprint(f\"Utility score is: {u:.3f}\")","execution_count":21,"outputs":[{"output_type":"stream","text":"Utility score is: 2861.313\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df[['Date', 'Action']].to_csv(f'LSTM_result_timestep{look_back}.csv')","execution_count":22,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}